{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Klasifikasi Sekuensial dengan RNN & LSTM\n",
    "\n",
    "Notebook ini mendemonstrasikan tugas klasifikasi sekuensial menggunakan Recurrent Neural Networks (RNN) dan Long Short-Term Memory (LSTM) di JAX dengan framework Flax NNX.\n",
    "\n",
    "## Eksperimen Orde Temporal (QRSU)\n",
    "Kita akan mereplikasi eksperimen dari Hochreiter & Schmidhuber (1997) yang menguji kemampuan jaringan saraf rekuren dalam menangkap ketergantungan temporal jangka panjang. Tugasnya adalah mengklasifikasikan urutan simbol berdasarkan urutan kemunculan simbol-simbol tertentu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory_rnn",
   "metadata": {},
   "source": [
    "## Konsep Dasar Pemodelan Sekuensial\n",
    "\n",
    "Data sekuensial adalah data di mana urutan kemunculan elemen sangat penting (misalnya: teks, audio, atau deret waktu). Untuk memodelkan data ini, kita membutuhkan arsitektur yang memiliki \"memori\" untuk mengingat informasi dari langkah waktu sebelumnya.\n",
    "\n",
    "### 1. Vanilla Recurrent Neural Networks (RNN)\n",
    "\n",
    "RNN bekerja dengan cara memproses elemen satu per satu sambil mempertahankan *hidden state* ($h_t$). *Hidden state* ini bertindak sebagai memori jangka pendek yang diperbarui pada setiap langkah waktu $t$:\n",
    "\n",
    "$$h_t = \\sigma(W_{hh} h_{t-1} + W_{xh} x_t + b_h)$$\n",
    "\n",
    "Di mana:\n",
    "- $x_t$ adalah input pada waktu $t$.\n",
    "- $h_{t-1}$ adalah memori dari langkah sebelumnya.\n",
    "- $\\sigma$ adalah fungsi aktivasi (biasanya tanh atau ReLU).\n",
    "\n",
    "**Kelemahan RNN:** Mengalami masalah *Vanishing Gradient*, di mana sinyal gradien mengecil secara eksponensial saat merambat mundur melalui waktu yang lama, sehingga sulit untuk mempelajari ketergantungan jangka panjang (long-term dependencies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory_lstm",
   "metadata": {},
   "source": [
    "### 2. Long Short-Term Memory (LSTM)\n",
    "\n",
    "LSTM dirancang khusus untuk mengatasi masalah *vanishing gradient* dengan memperkenalkan *Cell State* ($c_t$) dan mekanisme pintu (*gating system*):\n",
    "\n",
    "- **Forget Gate ($f_t$):** Menentukan informasi apa yang harus dibuang dari memori.\n",
    "- **Input Gate ($i_t$):** Menentukan informasi baru apa yang akan disimpan ke dalam memori.\n",
    "- **Output Gate ($o_t$):** Menentukan apa yang akan dikeluarkan sebagai *hidden state* $h_t$ selanjutnya.\n",
    "\n",
    "Aliran informasi dalam LSTM dikontrol oleh operasi perkalian elemen-per-elemen, memungkinkan informasi tetap tersimpan atau dibuang dengan sangat selektif selama ribuan langkah waktu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory_classification",
   "metadata": {},
   "source": [
    "### 3. Arsitektur Klasifikasi Sekuensial\n",
    "\n",
    "Dalam tugas klasifikasi ini, kita menggunakan pendekatan **Many-to-One**:\n",
    "1. Seluruh urutan $x_1, x_2, ..., x_T$ dimasukkan ke dalam RNN/LSTM.\n",
    "2. Kita mengambil *hidden state* terakhir ($h_T$) yang diasumsikan sebagai ringkasan (vektor representasi) dari seluruh urutan tersebut.\n",
    "3. Vektor $h_T$ dimasukkan ke lapisan *Linear* (Fully Connected) untuk menghasilkan probabilitas kelas melalui fungsi Softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "### Langkah 1: Pengaturan Awal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from time import process_time\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import optax\n",
    "\n",
    "# Menambahkan parent directory ke path agar bisa import modul lokal\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "from sequential_tasks import TemporalOrderExp6aSequence as QRSU\n",
    "from model_utils import save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "### Langkah 2: Konfigurasi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "model_type = \"lstm\" # atau \"rnn\"\n",
    "difficulty = \"easy\"\n",
    "batch_size = 32\n",
    "\n",
    "difficulty_levels = {\n",
    "    \"easy\": QRSU.DifficultyLevel.EASY,\n",
    "    \"normal\": QRSU.DifficultyLevel.NORMAL,\n",
    "    \"moderate\": QRSU.DifficultyLevel.MODERATE,\n",
    "    \"hard\": QRSU.DifficultyLevel.HARD,\n",
    "    \"nightmare\": QRSU.DifficultyLevel.NIGHTMARE\n",
    "}\n",
    "\n",
    "difficulty_level = difficulty_levels.get(difficulty, QRSU.DifficultyLevel.EASY)\n",
    "\n",
    "# Setup generator data\n",
    "train_data_gen = QRSU.get_predefined_generator(difficulty_level, batch_size)\n",
    "test_data_gen = QRSU.get_predefined_generator(difficulty_level, batch_size)\n",
    "MODEL_DIR = \"../models\"\n",
    "\n",
    "checkpoint_dir = f\"{MODEL_DIR}/seq_classification\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "### Langkah 3: Definisi Model\n",
    "\n",
    "Di bawah ini adalah implementasi `SimpleRNN` dan `SimpleLSTM` menggunakan Flax NNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "models",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nnx.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, rngs: nnx.Rngs):\n",
    "        self.rnn_cell = nnx.SimpleCell(input_size, hidden_size, rngs=rngs)\n",
    "        self.linear = nnx.Linear(hidden_size, output_size, rngs=rngs)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        h = jnp.zeros((batch_size, self.hidden_size))\n",
    "        h_list = []\n",
    "        for t in range(seq_len):\n",
    "            h, h_out = self.rnn_cell(h, x[:, t, :])\n",
    "            h = nnx.relu(h)\n",
    "            h_list.append(h)\n",
    "        h_stacked = jnp.stack(h_list, axis=1)\n",
    "        return self.linear(h_stacked)\n",
    "\n",
    "class SimpleLSTM(nnx.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, rngs: nnx.Rngs):\n",
    "        self.lstm_cell = nnx.LSTMCell(input_size, hidden_size, rngs=rngs)\n",
    "        self.linear = nnx.Linear(hidden_size, output_size, rngs=rngs)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        h = jnp.zeros((batch_size, self.hidden_size))\n",
    "        c = jnp.zeros((batch_size, self.hidden_size))\n",
    "        h_list = []\n",
    "        for t in range(seq_len):\n",
    "            (h, c), h_out = self.lstm_cell((h, c), x[:, t, :])\n",
    "            h_list.append(h_out)\n",
    "        h_stacked = jnp.stack(h_list, axis=1)\n",
    "        return self.linear(h_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "### Langkah 4: Fungsi Pelatihan\n",
    "\n",
    "Fungsi `train_step` menangani penghitungan gradien dan pembaruan bobot, sedangkan `train_epoch` mengulangi proses tersebut untuk seluruh dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "train_fns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, metrics, batch):\n",
    "    inputs, targets = batch\n",
    "    \n",
    "    def loss_fn(model):\n",
    "        logits = model(inputs)[:, -1, :] # Ambil output terakhir\n",
    "        target_idx = jnp.argmax(targets, axis=1)\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(logits, target_idx).mean()\n",
    "        return loss, logits\n",
    "\n",
    "    (loss, logits), grads = nnx.value_and_grad(loss_fn, has_aux=True)(model)\n",
    "    optimizer.update(model, grads)\n",
    "    \n",
    "    target_idx = jnp.argmax(targets, axis=1)\n",
    "    metrics.update(values=loss, logits=logits, labels=target_idx)\n",
    "    return loss\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model, metrics, batch):\n",
    "    inputs, targets = batch\n",
    "    logits = model(inputs)[:, -1, :]\n",
    "    target_idx = jnp.argmax(targets, axis=1)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, target_idx).mean()\n",
    "    metrics.update(values=loss, logits=logits, labels=target_idx)\n",
    "    return loss\n",
    "\n",
    "def train_epoch(model, datagen, optimizer, metrics):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for idx in range(len(datagen)):\n",
    "        x, y = datagen[idx]\n",
    "        loss = train_step(model, optimizer, metrics, (jnp.array(x), jnp.array(y)))\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(datagen)\n",
    "\n",
    "def evaluate(model, datagen, metrics):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    for idx in range(len(datagen)):\n",
    "        x, y = datagen[idx]\n",
    "        loss = eval_step(model, metrics, (jnp.array(x), jnp.array(y)))\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5",
   "metadata": {},
   "source": [
    "### Langkah 5: Inisialisasi Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "init",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_data_gen.n_symbols\n",
    "hidden_size = 64\n",
    "output_size = train_data_gen.n_classes    \n",
    "\n",
    "rngs = nnx.Rngs(42)\n",
    "if model_type == \"rnn\":\n",
    "    model = SimpleRNN(input_size, hidden_size, output_size, rngs=rngs)\n",
    "else:\n",
    "    model = SimpleLSTM(input_size, hidden_size, output_size, rngs=rngs)\n",
    "\n",
    "optimizer = nnx.Optimizer(model, optax.adam(1e-4), wrt=nnx.Param)\n",
    "metrics = nnx.MultiMetric(\n",
    "    loss=nnx.metrics.Average(),\n",
    "    accuracy=nnx.metrics.Accuracy(),\n",
    ")\n",
    "\n",
    "history = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6",
   "metadata": {},
   "source": [
    "### Langkah 6: Loop Pelatihan Utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai pelatihan lstm pada tingkat kesulitan easy...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e317a2a32f4098b3784f190697ca52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model disimpan ke ../models/seq_classification/epoch_1.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_2.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_3.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_4.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_5.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_6.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_7.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_8.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_9.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_10.safetensors\n",
      "Epoch 10: Loss=1.2088, Acc=0.7802, Test Acc=0.8165\n",
      "Model disimpan ke ../models/seq_classification/epoch_11.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_12.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_13.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_14.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_15.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_16.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_17.safetensors\n",
      "Model disimpan ke ../models/seq_classification/epoch_18.safetensors\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memulai pelatihan {model_type} pada tingkat kesulitan {difficulty}...\")\n",
    "\n",
    "for ep in tqdm(range(max_epochs), unit=\"epoch\"):\n",
    "    metrics.reset()\n",
    "    train_loss = train_epoch(model, train_data_gen, optimizer, metrics)\n",
    "    train_acc = metrics.compute()[\"accuracy\"]\n",
    "    \n",
    "    metrics.reset()\n",
    "    test_loss = evaluate(model, test_data_gen, metrics)\n",
    "    test_acc = metrics.compute()[\"accuracy\"]\n",
    "    \n",
    "    history[\"train_loss\"].append(float(train_loss))\n",
    "    history[\"train_acc\"].append(float(train_acc))\n",
    "    history[\"test_loss\"].append(float(test_loss))\n",
    "    history[\"test_acc\"].append(float(test_acc))\n",
    "\n",
    "    # Simpan checkpoint setiap epoch\n",
    "    if (ep + 1) % 10 == 0:\n",
    "        save_checkpoint(model, ep + 1, filedir=checkpoint_dir)\n",
    "        print(f\"Epoch {ep+1}: Loss={train_loss:.4f}, Acc={train_acc:.4f}, Test Acc={test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7",
   "metadata": {},
   "source": [
    "### Langkah 7: Visualisasi Hasil\n",
    "\n",
    "Meninjau grafik akurasi dan loss untuk melihat seberapa cepat model belajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"test_loss\"], label=\"Test Loss\")\n",
    "plt.title(\"Loss\"); plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(history[\"test_acc\"], label=\"Test Acc\")\n",
    "plt.title(\"Akurasi\"); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d00e8a",
   "metadata": {},
   "source": [
    "### Langkah 8: Menyimpan dan Memuat Model\n",
    "\n",
    "Salah satu aspek penting dalam deep learning adalah kemampuan untuk menyimpan state model (parameter) sehingga kita tidak perlu melatih ulang dari awal. Kita menggunakan format `safetensors` karena aman, efisien, dan cepat.\n",
    "\n",
    "**Alasan Menggunakan Safetensors:**\n",
    "1.  **Keamanan**: Tidak mengizinkan eksekusi kode saat memuat (berbeda dengan `pickle`).\n",
    "2.  **Efisiensi**: *Zero-copy* saat memuat ke memori, sangat cepat terutama untuk model besar.\n",
    "3.  **Interoperabilitas**: Format standar yang didukung banyak framework (PyTorch, JAX, TensorFlow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo Memuat Model\n",
    "print(\"Mencoba memuat model dari checkpoint terakhir...\")\n",
    "checkpoint_path = f\"{checkpoint_dir}/epoch_{max_epochs}.safetensors\"\n",
    "\n",
    "# 1. Inisialisasi model baru dengan arsitektur yang sama\n",
    "# Pastikan rngs diinisialisasi ulang\n",
    "new_rngs = nnx.Rngs(0)\n",
    "if model_type == \"rnn\":\n",
    "    model_baru = SimpleRNN(input_size, hidden_size, output_size, rngs=new_rngs)\n",
    "else:\n",
    "    model_baru = SimpleLSTM(input_size, hidden_size, output_size, rngs=new_rngs)\n",
    "\n",
    "# 2. Muat parameter\n",
    "load_checkpoint(model_baru, checkpoint_path)\n",
    "\n",
    "# 3. Verifikasi: Output harus identik dengan model asli\n",
    "# Ambil satu batch testing\n",
    "x_test, y_test = test_data_gen[0]\n",
    "test_input = jnp.array(x_test)\n",
    "\n",
    "model.eval()\n",
    "model_baru.eval()\n",
    "\n",
    "output_asli = model(test_input)[:, -1, :]\n",
    "output_baru = model_baru(test_input)[:, -1, :]\n",
    "\n",
    "diff = jnp.abs(output_asli - output_baru).max()\n",
    "print(f\"Perbedaan maksimum output: {diff:.6f}\")\n",
    "\n",
    "if diff < 1e-5:\n",
    "    print(\"VERIFIKASI BERHASIL: Model dimuat dengan benar!\")\n",
    "else:\n",
    "    print(\"VERIFIKASI GAGAL: Ada perbedaan output.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
