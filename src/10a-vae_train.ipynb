{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Training on MNIST Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all relevant modules\n",
    "import os\n",
    "import time as timer\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from skimage.util import random_noise\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "import torchvision.utils as vutils\n",
    "from torchviz import make_dot\n",
    "\n",
    "import res.viz_utils as vu\n",
    "from res.plot_lib import set_default\n",
    "\n",
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\"\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 30\n",
    "DATASET = 'mnist'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to (-1, 1) \n",
    "img_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "if DATASET == 'mnist':\n",
    "    dataset_func = datasets.MNIST\n",
    "elif DATASET == 'fmnist':\n",
    "    dataset_func = datasets.FashionMNIST\n",
    "\n",
    "# Load train\n",
    "train_data = dataset_func(\n",
    "    root=DATA_DIR,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=img_transform,\n",
    ")\n",
    "\n",
    "# Load test\n",
    "test_data = dataset_func(\n",
    "    root=DATA_DIR,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=img_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture and loss function\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size ** 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size ** 2, hidden_size * 2),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size ** 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size ** 2, input_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new_empty(std.size()).normal_()\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mu_logvar = self.encoder(x)\n",
    "        mu_logvar = mu_logvar.view(-1, 2, self.hidden_size)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        xr = self.decode(z)\n",
    "        return xr, mu, logvar\n",
    "    \n",
    "def vae_loss(x_hat, x, mu, logvar, beta=1):\n",
    "    rec_loss = nn.functional.mse_loss(x_hat, x, reduction=\"sum\")\n",
    "    kl_loss = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "\n",
    "    vae_loss = rec_loss + beta * kl_loss\n",
    "    return vae_loss, rec_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n, dx1, dx2] = train_data.data.size()\n",
    "input_size = dx1 * dx2\n",
    "hidden_size = 20\n",
    "beta =  1\n",
    "fixed_noise = torch.randn(64, hidden_size, device=DEVICE)\n",
    "\n",
    "model = VariationalAutoencoder(input_size, hidden_size).to(DEVICE)\n",
    "\n",
    "criterion = vae_loss\n",
    "optimizer = optim.Adam(\n",
    "    lr=1e-3,\n",
    "    params=model.parameters()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb Cell 9\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Xr, Mu, Logvar \u001b[39m=\u001b[39m model(train_data\u001b[39m.\u001b[39mdata[:\u001b[39m10\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb Cell 9\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     z, mu, logvar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     xr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(z)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m xr, mu, logvar\n",
      "\u001b[1;32m/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb Cell 9\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     mu_logvar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     mu_logvar \u001b[39m=\u001b[39m mu_logvar\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     mu \u001b[39m=\u001b[39m mu_logvar[:, \u001b[39m0\u001b[39m, :]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "X = train_data.data[:10]\n",
    "Xr, Mu, Logvar = model(train_data.data[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = \"vae\" \n",
    "model_path = os.path.join(MODEL_DIR, f\"{mname}_{DATASET}_z{hidden_size}_ep{NUM_EPOCH}.pth\")\n",
    "\n",
    "sample_dir = os.path.join(MODEL_DIR, f\"{mname}_samples_{DATASET}\")\n",
    "\n",
    "# create SAMPLE_DIR if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    print(f'The new directory {sample_dir} has been created')\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    start_t = timer.time()\n",
    "    for batch_idx, (X, _) in enumerate(train_loader):\n",
    "        \n",
    "        # Feed forward\n",
    "        X = X.view(-1, input_size).to(DEVICE)\n",
    "        \n",
    "        Xr, Mu, Logvar = model(X)\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        vae_loss, rec_loss, kl_loss = criterion(Xr, X, Mu, Logvar, beta=beta)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        vae_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                Rec = model.decode(fixed_noise)\n",
    "            \n",
    "            Rec = Rec.view(-1, 1, dx1, dx2)\n",
    "            # vutils.save_image(Input, f'{sample_dir}/original.png', normalize=True)\n",
    "            vutils.save_image(Rec, f'{sample_dir}/reconstruction-{epoch+1}_batch-{batch_idx}.png', normalize=True)\n",
    "\n",
    "        \n",
    "    # end for\n",
    "    elapsed_t = timer.time() - start_t\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCH}], vae_loss: {vae_loss.item():.4f}, rec_loss: {rec_loss.item():.4f}, kl_loss: {kl_loss.item():.4f}, elapsed_t: {elapsed_t: 0.2f} secs')\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\" ---- Model {model_path} stored!\")\n",
    "\n",
    "    # Display input images and their reconstructions\n",
    "    Input = X.view(-1, 1, dx1, dx2).detach().cpu().numpy()\n",
    "    Rec = Xr.view(-1, 1, dx1, dx2).detach().cpu().numpy()\n",
    "    grid_x = vu.set_grid(Input, num_cells=5)\n",
    "    vu.show(grid_x)\n",
    "\n",
    "    grid_xr = vu.set_grid(Rec, num_cells=5)\n",
    "    vu.show(grid_xr)\n",
    "# end for"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
