{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Training on MNIST Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all relevant modules\n",
    "import os\n",
    "import time as timer\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from skimage.util import random_noise\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "import torchvision.utils as vutils\n",
    "from torchviz import make_dot\n",
    "\n",
    "import res.viz_utils as vu\n",
    "from res.plot_lib import set_default\n",
    "\n",
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\"\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 30\n",
    "DATASET = 'mnist'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading train-images-idx3-ubyte.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     dataset_func \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mFashionMNIST\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Load train\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m train_data \u001b[39m=\u001b[39m dataset_func(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     root\u001b[39m=\u001b[39mDATA_DIR,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     transform\u001b[39m=\u001b[39mimg_transform,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Load test\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m test_data \u001b[39m=\u001b[39m dataset_func(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     root\u001b[39m=\u001b[39mDATA_DIR,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     transform\u001b[39m=\u001b[39mimg_transform,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mghifary/Work/govtech/codes/AI/IF5281/10a-vae_train.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/torchvision/datasets/mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[1;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/torchvision/datasets/mnist.py:195\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError downloading \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error downloading train-images-idx3-ubyte.gz"
     ]
    }
   ],
   "source": [
    "# Transform to (-1, 1) \n",
    "img_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "if DATASET == 'mnist':\n",
    "    dataset_func = datasets.MNIST\n",
    "elif DATASET == 'fmnist':\n",
    "    dataset_func = datasets.FashionMNIST\n",
    "\n",
    "# Load train\n",
    "train_data = dataset_func(\n",
    "    root=DATA_DIR,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=img_transform,\n",
    ")\n",
    "\n",
    "# Load test\n",
    "test_data = dataset_func(\n",
    "    root=DATA_DIR,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=img_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture and loss function\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size ** 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size ** 2, hidden_size * 2),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size ** 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size ** 2, input_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new_empty(std.size()).normal_()\n",
    "            return eps.mul_(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mu_logvar = self.encoder(x)\n",
    "        mu_logvar = mu_logvar.view(-1, 2, self.hidden_size)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        xr = self.decode(z)\n",
    "        return xr, mu, logvar\n",
    "    \n",
    "def vae_loss(x_hat, x, mu, logvar, beta=1):\n",
    "    rec_loss = nn.functional.mse_loss(x_hat, x, reduction=\"sum\")\n",
    "    kl_loss = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "\n",
    "    vae_loss = rec_loss + beta * kl_loss\n",
    "    return vae_loss, rec_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n, dx1, dx2] = train_data.data.size()\n",
    "input_size = dx1 * dx2\n",
    "hidden_size = 20\n",
    "beta =  1\n",
    "fixed_noise = torch.randn(64, hidden_size, device=DEVICE)\n",
    "\n",
    "model = VariationalAutoencoder(input_size, hidden_size).to(DEVICE)\n",
    "\n",
    "criterion = vae_loss\n",
    "optimizer = optim.Adam(\n",
    "    lr=1e-3,\n",
    "    params=model.parameters()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = \"vae\" \n",
    "model_path = os.path.join(MODEL_DIR, f\"{mname}_{DATASET}_z{hidden_size}_ep{NUM_EPOCH}.pth\")\n",
    "\n",
    "sample_dir = os.path.join(MODEL_DIR, f\"{mname}_samples_{DATASET}\")\n",
    "\n",
    "# create SAMPLE_DIR if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    print(f'The new directory {sample_dir} has been created')\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    start_t = timer.time()\n",
    "    for batch_idx, (X, _) in enumerate(train_loader):\n",
    "        \n",
    "        # Feed forward\n",
    "        X = X.view(-1, input_size).to(DEVICE)\n",
    "        \n",
    "        Xr, Mu, Logvar = model(X)\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        vae_loss, rec_loss, kl_loss = criterion(Xr, X, Mu, Logvar, beta=beta)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        vae_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                Rec = model.decode(fixed_noise)\n",
    "            \n",
    "            Rec = Rec.view(-1, 1, dx1, dx2)\n",
    "            # vutils.save_image(Input, f'{sample_dir}/original.png', normalize=True)\n",
    "            vutils.save_image(Rec, f'{sample_dir}/reconstruction-{epoch+1}_batch-{batch_idx}.png', normalize=True)\n",
    "\n",
    "        \n",
    "    # end for\n",
    "    elapsed_t = timer.time() - start_t\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCH}], vae_loss: {vae_loss.item():.4f}, rec_loss: {rec_loss.item():.4f}, kl_loss: {kl_loss.item():.4f}, elapsed_t: {elapsed_t: 0.2f} secs')\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\" ---- Model {model_path} stored!\")\n",
    "\n",
    "    # Display input images and their reconstructions\n",
    "    Input = X.view(-1, 1, dx1, dx2).detach().cpu().numpy()\n",
    "    Rec = Xr.view(-1, 1, dx1, dx2).detach().cpu().numpy()\n",
    "    grid_x = vu.set_grid(Input, num_cells=5)\n",
    "    vu.show(grid_x)\n",
    "\n",
    "    grid_xr = vu.set_grid(Rec, num_cells=5)\n",
    "    vu.show(grid_xr)\n",
    "# end for"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
